{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb9b73a-9652-4676-b3ea-114c9f3e95ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets scikit-learn matplotlib numpy -q >> None\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029326ad-ac25-4ed6-b8fa-81398cddb226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Astroformer'...\n",
      "remote: Enumerating objects: 580, done.\u001b[K\n",
      "remote: Counting objects: 100% (580/580), done.\u001b[K\n",
      "remote: Compressing objects: 100% (355/355), done.\u001b[K\n",
      "remote: Total 580 (delta 222), reused 570 (delta 218), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (580/580), 2.39 MiB | 3.68 MiB/s, done.\n",
      "Resolving deltas: 100% (222/222), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Rishit-dagli/Astroformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0db92ab-0800-470f-96e9-8b1afb8e16cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images\n",
      "Processed 1000 images\n",
      "Processed 2000 images\n",
      "Processed 3000 images\n",
      "Processed 4000 images\n",
      "Processed 5000 images\n",
      "Processed 6000 images\n",
      "Processed 7000 images\n",
      "Processed 8000 images\n",
      "Processed 9000 images\n",
      "Processed 10000 images\n",
      "Processed 11000 images\n",
      "Processed 12000 images\n",
      "Processed 13000 images\n",
      "Processed 14000 images\n",
      "Processed 15000 images\n",
      "Extracted and resized 15962 images to 224x224 pixels in galaxy10_images\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Image\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Load the dataset\n",
    "dataset_name = \"matthieulel/galaxy10_decals\"\n",
    "galaxy_dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Make sure the image column is properly cast as Image type\n",
    "if not isinstance(galaxy_dataset[\"train\"].features[\"image\"], Image):\n",
    "    galaxy_dataset = galaxy_dataset.cast_column(\"image\", Image())\n",
    "\n",
    "# Create directories for each class\n",
    "class_names = {\n",
    "    0: \"Disturbed_Galaxies\",\n",
    "    1: \"Merging_Galaxies\",\n",
    "    2: \"Round_Smooth_Galaxies\",\n",
    "    3: \"In-between_Round_Smooth_Galaxies\",\n",
    "    4: \"Cigar_Shaped_Smooth_Galaxies\",\n",
    "    5: \"Barred_Spiral_Galaxies\",\n",
    "    6: \"Unbarred_Tight_Spiral_Galaxies\",\n",
    "    7: \"Unbarred_Loose_Spiral_Galaxies\",\n",
    "    8: \"Edge-on_Galaxies_without_Bulge\",\n",
    "    9: \"Edge-on_Galaxies_with_Bulge\"\n",
    "}\n",
    "\n",
    "output_dir = \"galaxy10_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for class_idx, class_name in class_names.items():\n",
    "    os.makedirs(os.path.join(output_dir, f\"{class_idx}_{class_name}\"), exist_ok=True)\n",
    "\n",
    "# Extract, resize, and save images\n",
    "for i, example in enumerate(galaxy_dataset[\"train\"]):\n",
    "    img = example[\"image\"]\n",
    "    label = example[\"label\"]\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Resize the image to 224x224 pixels using ANTIALIAS for better quality\n",
    "    img_resized = img.resize((224, 224), PILImage.LANCZOS)\n",
    "    \n",
    "    # Save the resized image\n",
    "    img_path = os.path.join(output_dir, f\"{label}_{class_name}\", f\"galaxy_{i}.png\")\n",
    "    img_resized.save(img_path)\n",
    "    \n",
    "    # Print progress\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processed {i} images\")\n",
    "\n",
    "print(f\"Extracted and resized {len(galaxy_dataset['train'])} images to 224x224 pixels in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cf5672-7c41-4376-817b-69a129bd6303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/svf_knowledge_editing/Astroformer/pytorch-image-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd Astroformer/pytorch-image-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ae0273-a949-4b4f-9fdf-60e54f9ee84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.3\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.11.1.6\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.3.0\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.0.4\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.6.77\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.1.2\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.6.80\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.4.2\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.13.2)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.6.77\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 KB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.7.77\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.5.1.17\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.26.2\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.6.85\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.0->torch) (59.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.2.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.13.3 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52274be9-fddb-430a-b6b4-db0971c496e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with a single process on 1 device (cuda:0).\n",
      "WARNING: No pretrained configuration specified for astroformer_4 model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model astroformer_4 created, param count:241083274\n",
      "Data processing configuration for current model + dataset:\n",
      "\tinput_size: (3, 256, 256)\n",
      "\tinterpolation: bicubic\n",
      "\tmean: (0.485, 0.456, 0.406)\n",
      "\tstd: (0.229, 0.224, 0.225)\n",
      "\tcrop_pct: 0.875\n",
      "\tcrop_mode: center\n",
      "Learning rate (3.952847075210474e-06) calculated from base learning rate (2e-05) and effective global batch size (10) with sqrt scaling.\n",
      "AMP not enabled. Training in float32.\n",
      "Scheduled epochs: 300. LR stepped per epoch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/train.py\", line 1075, in <module>\n",
      "    main()\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/train.py\", line 772, in main\n",
      "    train_metrics = train_one_epoch(\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/train.py\", line 935, in train_one_epoch\n",
      "    loss = _forward()\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/train.py\", line 902, in _forward\n",
      "    output = model(input)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/timm/models/astroformer.py\", line 1366, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/timm/models/astroformer.py\", line 1358, in forward_features\n",
      "    x = self.stages(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/timm/models/astroformer.py\", line 1132, in forward\n",
      "    x = self.blocks(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/timm/models/astroformer.py\", line 473, in forward\n",
      "    self.ls1(self.attn(self.norm1(x), shared_rel_pos=shared_rel_pos))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/app/svf_knowledge_editing/Astroformer/pytorch-image-models/timm/models/astroformer.py\", line 194, in forward\n",
      "    torch.nn.functional.scaled_dot_product_attention(\n",
      "RuntimeError: The expanded size of the tensor (64) must match the existing size (49) at non-singleton dimension 3.  Target sizes: [10, 48, 64, 64].  Tensor sizes: [1, 48, 49, 49]\n",
      "E0427 09:22:50.176000 11244 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 11309) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 892, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 883, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 139, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 270, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-04-27_09:22:50\n",
      "  host      : abd661773e58\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 11309)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!sh distributed_train.sh 1 galaxy10_images --train-split 0.8 --val-split 0.2 --model astroformer_4 --num-classes 10 --img-size 224 --in-chans 3 --input-size 3 256 256 --batch-size 10 --grad-accum-steps 1 --opt adamw --sched cosine --lr-base 2e-5 --lr-cycle-decay 1e-2 --lr-k-decay 1 --warmup-lr 1e-5 --epochs 300 --warmup-epochs 5 --mixup 0.8 --smoothing 0.1 --drop 0.1 --save-images --output result_ours/astroformer_4_galaxy10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4b1288-d88f-4d36-9f36-07e515373834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "shm              64M  4.0K   64M   1% /dev/shm\n"
     ]
    }
   ],
   "source": [
    "!df -h /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cca3e-c6c9-4d2e-8d43-21016870b7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
