{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37939f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "\n",
    "# Load the Galaxy10 dataset from Hugging Face\n",
    "dataset_name = \"matthieulel/galaxy10_decals\"\n",
    "galaxy_dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(180),  # Galaxies can appear at any orientation\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Slight zoom variation\n",
    "    # transforms.RandomHorizontalFlip(),  # Horizontal flip is valid for galaxies\n",
    "    # transforms.RandomVerticalFlip(),   # Vertical flip is also valid for galaxies\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Simulate different telescope exposures\n",
    "    transforms.ToTensor(),\n",
    "    # Add any other necessary transformations\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # Add any other necessary transformations\n",
    "])\n",
    "\n",
    "# Define preprocessing functions to apply transformations\n",
    "def preprocess_train(examples, transform=None):\n",
    "    examples[\"pixel_values\"] = [transform(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "def preprocess_test(examples, transform=None):\n",
    "    examples[\"pixel_values\"] = [transform(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "# Create a validation split if none exists\n",
    "train_dataset = galaxy_dataset[\"train\"].map(\n",
    "    partial(preprocess_train, transform=train_transform),\n",
    "    batched=True,\n",
    "    remove_columns=[\"image\"]\n",
    ")\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"label\"])\n",
    "\n",
    "if \"test\" in galaxy_dataset:\n",
    "    test_dataset = galaxy_dataset[\"test\"].map(\n",
    "        partial(preprocess_test, transform=test_transform),\n",
    "        batched=True,\n",
    "        remove_columns=[\"image\"]\n",
    "    )\n",
    "    test_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"label\"])\n",
    "\n",
    "# Define a custom collate function to handle the format\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
    "    labels = torch.tensor([item[\"label\"] for item in batch])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 4  # Adjust based on your system\n",
    "prefetch_factor = 2\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    # pin_memory=True,\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "if 'test' in galaxy_dataset:\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        # pin_memory=True,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        prefetch_factor=prefetch_factor,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "# Verify the dataloaders\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "if 'test' in galaxy_dataset:\n",
    "    print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "# Example of iterating through the dataloader\n",
    "for batch in train_loader:\n",
    "    print(f\"Pixel values shape: {batch['pixel_values'].shape}\")\n",
    "    print(f\"Labels shape: {batch['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights\n",
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "# Define the AttentionHead class\n",
    "class AdvancedMLPHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(in_features)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),  # Add dropout\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),  # Add dropout\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) > 2:\n",
    "            x = x[:, 0]  # Take only the CLS token\n",
    "        x = self.norm(x)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# Load the model architecture (without pretrained weights)\n",
    "model = vit_l_16(weights=ViT_L_16_Weights.DEFAULT)\n",
    "# Get the number of features in the final layer\n",
    "num_features = model.heads.head.in_features\n",
    "\n",
    "# Replace the classifier head with the AttentionHead\n",
    "num_classes = 10  # For Galaxy10 DECals dataset\n",
    "model.heads.head = AdvancedMLPHead(num_features, 2048, num_classes)\n",
    "\n",
    "# # Load the saved model weights from the .pt file\n",
    "# model.load_state_dict(torch.load('best_galaxy_vit_model.pth'))\n",
    "\n",
    "# Unfreeze all parameters for training the entire model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-large-patch16-224\")\n",
    "\n",
    "# Define optimizer and loss function for all parameters\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,  # Lower learning rate for fine-tuning the entire model\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0.05\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='max', factor=0.1, patience=3,\n",
    "# )\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=5,  # Restart every 5 epochs\n",
    "    T_mult=1,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Track best validation accuracy for model saving\n",
    "best_val_acc = 0.0\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    # Create a new iterator for each epoch\n",
    "    train_loader_iter = iter(train_loader)\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\") as pbar:\n",
    "        for batch_idx in range(num_batches):\n",
    "            try:\n",
    "                # Get the next batch\n",
    "                batch = next(train_loader_iter)\n",
    "            except StopIteration:\n",
    "                # If we've run out of data, break the loop\n",
    "                break\n",
    "\n",
    "            # Unpack the batch - assuming batch contains images and labels\n",
    "            if isinstance(batch, dict):\n",
    "                images, labels = batch['pixel_values'], batch['labels']\n",
    "            else:\n",
    "                images, labels = batch\n",
    "                # Process images with feature extractor\n",
    "                inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "                images = inputs['pixel_values']\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # For torchvision ViT, don't use pixel_values parameter\n",
    "            logits = outputs if not hasattr(outputs, 'logits') else outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + batch_idx / num_batches)\n",
    "\n",
    "            # Track statistics\n",
    "            train_losses.append(loss.item())\n",
    "            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            train_preds.extend(batch_preds)\n",
    "            batch_labels = labels.cpu().numpy()\n",
    "            train_labels.extend(batch_labels)\n",
    "\n",
    "            # Update progress bar\n",
    "            batch_acc = accuracy_score(batch_labels, batch_preds)\n",
    "            pbar.set_postfix(loss=loss.item(), acc=batch_acc)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_acc = accuracy_score(train_labels, train_preds)\n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Create iterator for validation data\n",
    "    val_dataloader_iter = iter(test_loader)\n",
    "    num_val_batches = len(test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=num_val_batches, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\") as pbar:\n",
    "            for _ in range(num_val_batches):\n",
    "                try:\n",
    "                    # Get the next batch\n",
    "                    batch = next(val_dataloader_iter)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "\n",
    "                # Unpack the batch - assuming batch contains images and labels\n",
    "                if isinstance(batch, dict):\n",
    "                    images, labels = batch['pixel_values'], batch['labels']\n",
    "                else:\n",
    "                    images, labels = batch\n",
    "                    # Process images with feature extractor\n",
    "                    inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "                    images = inputs['pixel_values']\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)  # For torchvision ViT, don't use pixel_values parameter\n",
    "                logits = outputs if not hasattr(outputs, 'logits') else outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                # Track statistics\n",
    "                val_losses.append(loss.item())\n",
    "                batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                val_preds.extend(batch_preds)\n",
    "                batch_labels = labels.cpu().numpy()\n",
    "                val_labels.extend(batch_labels)\n",
    "\n",
    "                # Update progress bar\n",
    "                batch_acc = accuracy_score(batch_labels, batch_preds)\n",
    "                pbar.set_postfix(loss=loss.item(), acc=batch_acc)\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "    # Update learning rate based on validation accuracy\n",
    "    # scheduler.step(val_acc)\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}, Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}')\n",
    "\n",
    "    # Save the best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_galaxy_vit_model_reg.pth')\n",
    "        print(f'Model saved with validation accuracy: {val_acc:.4f}') \n",
    "\n",
    "print(f'Training completed. Best validation accuracy: {best_val_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
